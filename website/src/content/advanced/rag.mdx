import { Tabs } from "nextra/components";

# Retrieval-Augmented Generation (RAG)

Alith supports Retrieval-Augmented Generation (RAG), a technique that combines retrieval of relevant information from a knowledge base with text generation. This allows agents to provide more accurate and context-aware responses by leveraging external data.

<Tabs items={['Rust', 'Python', 'Node.js']}>
  <Tabs.Tab>

## RAG with Memory

```rust
use alith::{Agent, Chat, EmbeddingsBuilder, InMemoryStorage, LLM};

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let model = LLM::from_model_name("gpt-4")?;
    let embeddings_model = model.embeddings_model("text-embedding-3-small");
    let data = EmbeddingsBuilder::new(embeddings_model.clone())
        .documents(vec!["doc0", "doc1", "doc2"])
        .unwrap()
        .build()
        .await?;
    let storage = InMemoryStorage::from_multiple_documents(embeddings_model, data);

    let agent = Agent::new("simple agent", model)
        .preamble(
            r#"
You are a dictionary assistant here to assist the user in understanding the meaning of words.
You will find additional non-standard word definitions that could be useful below.
"#,
        )
        .store_index(1, storage);
    let response = agent.prompt("What does \"glarb-glarb\" mean?").await?;

    println!("{}", response);

    Ok(())
}
```

## RAG with Vector Database

```rust
use alith::store::qdrant::{
    CreateCollectionBuilder, Distance, QdrantClient, QdrantStorage, VectorParamsBuilder,
    DEFAULT_COLLECTION_NAME,
};
use alith::{Agent, Chat, EmbeddingsBuilder, LLM};

#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
    let model = LLM::from_model_name("gpt-4")?;
    let embeddings_model = model.embeddings_model("text-embedding-3-small");
    let data = EmbeddingsBuilder::new(embeddings_model.clone())
        .documents(vec!["doc0", "doc1", "doc2"])
        .unwrap()
        .build()
        .await?;

    let client = QdrantClient::from_url("http://localhost:6334").build()?;

    if !client.collection_exists(DEFAULT_COLLECTION_NAME).await? {
        client
            .create_collection(
                CreateCollectionBuilder::new(DEFAULT_COLLECTION_NAME)
                    .vectors_config(VectorParamsBuilder::new(1536, Distance::Cosine)),
            )
            .await?;
    }

    let storage = QdrantStorage::from_multiple_documents(client, embeddings_model, data).await?;

    let agent = Agent::new("simple agent", model)
        .preamble(
            r#"
You are a dictionary assistant here to assist the user in understanding the meaning of words.
You will find additional non-standard word definitions that could be useful below.
"#,
        )
        .store_index(1, storage);
    let response = agent.prompt("What does \"glarb-glarb\" mean?").await?;

    println!("{}", response);

    Ok(())
}
```

  </Tabs.Tab>

  <Tabs.Tab>

## RAG with Vector Database

```python
from pathlib import Path
from alith import Agent, MilvusStore, chunk_text

print(
    Agent(
        name="RAG Bot",
        model="gpt-4",
        preamble="I'm a RAG bot. Ask me anything!",
        store=MilvusStore().save_docs(chunk_text(Path("README.md").read_text())),
    ).prompt("What is Alith?")
)
```

  </Tabs.Tab>

  <Tabs.Tab>

## RAG with Vector Database

```typescript
import { Agent, Store, QdrantStore, RemoteModelEmbeddings } from "alith";

const store: Store = new QdrantStore(
  new RemoteModelEmbeddings(
    "your embeddings model name",
    "your API key",
    "base url",
  ),
);
await store.save("Hello, World");
const agent = new Agent({
  model: "gpt-4",
  preamble:
    "You are a comedian here to entertain the user using humour and jokes.",
  store,
});
console.log(await agent.prompt("Entertain me!"));
```

</Tabs.Tab>
</Tabs>
